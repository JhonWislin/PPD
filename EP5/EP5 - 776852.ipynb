{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Exercício Programa 5**\n","\n","Nome: Jhon Wislin Ribeiro Citron\n","\n","RA: 776852\n","\n","Professor: Hermes Senger\n"],"metadata":{"id":"G_RFVPyNypNu"}},{"cell_type":"markdown","source":["Abaixo é possível observar o código de multiplicação de matrizes. O objetivo é paralelizalo utilizando programação em CUDA de forma que o calculo seja dividido entre as threads da grid da GPU."],"metadata":{"id":"92iHuv4qzQ8R"}},{"cell_type":"code","source":["!lscpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cOW_OddG_YiW","executionInfo":{"status":"ok","timestamp":1706376945808,"user_tz":180,"elapsed":13,"user":{"displayName":"Jhon Wislin","userId":"08488951882543435445"}},"outputId":"f7ee3e8e-fb0d-46c1-d08a-51a748a22607"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Architecture:            x86_64\n","  CPU op-mode(s):        32-bit, 64-bit\n","  Address sizes:         46 bits physical, 48 bits virtual\n","  Byte Order:            Little Endian\n","CPU(s):                  2\n","  On-line CPU(s) list:   0,1\n","Vendor ID:               GenuineIntel\n","  Model name:            Intel(R) Xeon(R) CPU @ 2.00GHz\n","    CPU family:          6\n","    Model:               85\n","    Thread(s) per core:  2\n","    Core(s) per socket:  1\n","    Socket(s):           1\n","    Stepping:            3\n","    BogoMIPS:            4000.41\n","    Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clf\n","                         lush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_\n","                         good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fm\n","                         a cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hyp\n","                         ervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsb\n","                         ase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512d\n","                         q rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsave\n","                         c xgetbv1 xsaves arat md_clear arch_capabilities\n","Virtualization features: \n","  Hypervisor vendor:     KVM\n","  Virtualization type:   full\n","Caches (sum of all):     \n","  L1d:                   32 KiB (1 instance)\n","  L1i:                   32 KiB (1 instance)\n","  L2:                    1 MiB (1 instance)\n","  L3:                    38.5 MiB (1 instance)\n","NUMA:                    \n","  NUMA node(s):          1\n","  NUMA node0 CPU(s):     0,1\n","Vulnerabilities:         \n","  Gather data sampling:  Not affected\n","  Itlb multihit:         Not affected\n","  L1tf:                  Mitigation; PTE Inversion\n","  Mds:                   Vulnerable; SMT Host state unknown\n","  Meltdown:              Vulnerable\n","  Mmio stale data:       Vulnerable\n","  Retbleed:              Vulnerable\n","  Spec rstack overflow:  Not affected\n","  Spec store bypass:     Vulnerable\n","  Spectre v1:            Vulnerable: __user pointer sanitization and usercopy barriers only; no swap\n","                         gs barriers\n","  Spectre v2:            Vulnerable, IBPB: disabled, STIBP: disabled, PBRSB-eIBRS: Not affected\n","  Srbds:                 Not affected\n","  Tsx async abort:       Vulnerable\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nL7Bi2Id6IIS","executionInfo":{"status":"ok","timestamp":1707095656366,"user_tz":180,"elapsed":1014,"user":{"displayName":"Jhon Wislin","userId":"08488951882543435445"}},"outputId":"f4176daf-06e0-4280-c5b3-0d51a00c096e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Feb  5 01:13:44 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   52C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NPhYpvbjyjYK","executionInfo":{"status":"ok","timestamp":1707159184386,"user_tz":180,"elapsed":330,"user":{"displayName":"Jhon Wislin","userId":"08488951882543435445"}},"outputId":"f72300eb-358c-4dde-d347-c69b6411d96c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting ep5.cu\n"]}],"source":["%%writefile ep5.cu\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <time.h>\n","\n","__global__ void matrixMulGPU(int *a, int *b, int *c, int N)\n","{\n","    int X = blockIdx.y * blockDim.y + threadIdx.y; //Indíce global para x na grid\n","    int Y = blockIdx.x * blockDim.x + threadIdx.x; //Indice global para y na grid\n","    int strideX = blockDim.x * gridDim.x; //Número de threads em x\n","    int strideY = blockDim.y * gridDim.y; //Número de threads em y\n","\n","    for( int row = X; row < N; row+=strideX )\n","      for( int col = Y; col < N; col+=strideY )\n","      {\n","          int val = 0;\n","          for (int k = 0; k < N; ++k)\n","          {\n","              val += a[row * N + k] * b[k * N + col];\n","          }\n","          c[row * N + col] = val;\n","      }\n","}\n","\n","\n","/*\n"," * This CPU function already works, and will run to create a solution matrix\n"," * against which to verify your work building out the matrixMulGPU kernel.\n"," */\n","\n","void matrixMulCPU( int * a, int * b, int * c , int N)\n","{\n","  int val = 0;\n","\n","  for( int row = 0; row < N; ++row )\n","    for( int col = 0; col < N; ++col )\n","    {\n","      val = 0;\n","      for ( int k = 0; k < N; ++k )\n","        val += a[row * N + k] * b[k * N + col];\n","      c[row * N + col] = val;\n","    }\n","}\n","\n","int main(int argc, char *argv[])\n","{\n","  int *a, *b, *c_cpu, *c_gpu; // Allocate a solution matrix for both the CPU and the GPU operations\n","  // Para medir tempo de execução de um kernel\n","  cudaEvent_t start_gpu, stop_gpu;\n","  cudaEventCreate(&start_gpu);\n","  cudaEventCreate(&stop_gpu);\n","\n","  if (argc != 2)\n","  {\n","    printf(\"Usage: %s <N>\\n\", argv[0]);\n","    return 1;\n","  }\n","\n","  int N = atoi(argv[1]);\n","\n","  int size = N * N * sizeof (int); // Number of bytes of an N x N matrix\n","\n","  // Allocate memory\n","  cudaMallocManaged (&a, size);\n","  cudaMallocManaged (&b, size);\n","  cudaMallocManaged (&c_cpu, size);\n","  cudaMallocManaged (&c_gpu, size);\n","\n","  // Initialize memory; create 2D matrices\n","  for( int row = 0; row < N; ++row )\n","    for( int col = 0; col < N; ++col )\n","    {\n","      a[row*N + col] = row;//\n","      b[row*N + col] = col+2;\n","      c_cpu[row*N + col] = 0;\n","      c_gpu[row*N + col] = 0;\n","    }\n","\n","  /*\n","   * Assign `threads_per_block` and `number_of_blocks` 2D values\n","   * that can be used in matrixMulGPU above.\n","   */\n","\n","  dim3 threads_per_block(8,8);\n","  dim3 number_of_blocks(32,32);\n","\n","  cudaEventRecord(start_gpu);\n","\n","  matrixMulGPU <<< number_of_blocks, threads_per_block >>> ( a, b, c_gpu, N );\n","  cudaDeviceSynchronize();\n","\n","  cudaEventRecord(stop_gpu);\n","  cudaEventSynchronize(stop_gpu);\n","  float duration_gpu = 0;\n","  cudaEventElapsedTime(&duration_gpu, start_gpu, stop_gpu);\n","  printf(\"GPU Time: %lf seconds\\n\", duration_gpu);\n","\n","  // Call the CPU version to check our work\n","  clock_t start_cpu = clock();\n","\n","  matrixMulCPU( a, b, c_cpu, N );\n","\n","  clock_t stop_cpu = clock();\n","\n","  double duration_cpu = ((double)(stop_cpu - start_cpu)) / CLOCKS_PER_SEC;\n","  printf(\"CPU Time: %lf seconds\\n\", duration_cpu);\n","\n","  // Compare the two answers to make sure they are equal\n","  bool error = false;\n","  for( int row = 0; row < N && !error; ++row )\n","    for( int col = 0; col < N && !error; ++col )\n","      if (c_cpu[row * N + col] != c_gpu[row * N + col])\n","      {\n","        printf(\"FOUND ERROR at c[%d][%d]\\n\", row, col);\n","        error = true;\n","        break;\n","      }\n","  if (!error)\n","    printf(\"Success!\\n\");\n","\n","  // Free all our allocated memory\n","  cudaFree(a); cudaFree(b);\n","  cudaFree( c_cpu ); cudaFree( c_gpu );\n","}"]},{"cell_type":"code","source":["!nvcc -arch=sm_75 -o ep5 ep5.cu && ./ep5 10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NMJfkj3t6qsz","executionInfo":{"status":"ok","timestamp":1707159373390,"user_tz":180,"elapsed":1430,"user":{"displayName":"Jhon Wislin","userId":"08488951882543435445"}},"outputId":"0aa79d88-b43a-4a0d-d125-84c1963bb961"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU Time: 0.529344 seconds\n","CPU Time: 0.000063 seconds\n","Success!\n"]}]},{"cell_type":"code","source":["!nvcc -arch=sm_75 -o ep5 ep5.cu && ./ep5 100"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HtycxlYGEJXq","executionInfo":{"status":"ok","timestamp":1707159375855,"user_tz":180,"elapsed":2467,"user":{"displayName":"Jhon Wislin","userId":"08488951882543435445"}},"outputId":"1da737eb-c218-45a5-a953-b2b2db2dd22f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU Time: 0.799072 seconds\n","CPU Time: 0.004822 seconds\n","Success!\n"]}]},{"cell_type":"code","source":["!nvcc -arch=sm_75 -o ep5 ep5.cu && ./ep5 1000"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rXuJM1kOELAV","executionInfo":{"status":"ok","timestamp":1707159381214,"user_tz":180,"elapsed":5363,"user":{"displayName":"Jhon Wislin","userId":"08488951882543435445"}},"outputId":"a69f2631-f8f1-45f5-ae58-28cb923d0bee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU Time: 12.529856 seconds\n","CPU Time: 3.873425 seconds\n","Success!\n"]}]}]}